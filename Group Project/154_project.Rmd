---
title: "154_project"
author: "Jason Wang, Liam Toebes, Senjie Wang"
date: "November 23, 2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(stringr)
library(e1071)
library(tree)
library(splines)
library(corrplot)
library(randomForest)
library(caret)

epl=data.frame(read.csv("epldata_final.csv"))

#print(epl)
#barplot(table(epl$position))
#dim(model.matrix( ~ club + position +nationality- 1, data=epl ))

```

## Data wrangling

We combine columns of one-hot encoding of club, position, and nationality into epl data frame.

```{r}


epl$fpl_sel <- as.double(str_remove(epl$fpl_sel, "%$"))
epl <- cbind(epl, model.matrix( ~ club + position +nationality- 1, data=epl))
#epl
```

We remove columns we don't use and we clean up the NAs. Lastly, we split the data into training and test set. 

```{r}
#deleting unwanted columns
epl$name=NULL
epl$club=NULL
epl$position=NULL
#epl$page_views=NULL
#epl$fpl_value=NULL
epl$fpl_sel=NULL
#epl$fpl_points=NULL
epl$nationality=NULL
epl$age_cat=NULL
#epl$club_id=NULL

#head(epl)
epl=na.omit(epl)
factors=c('position_cat','region','big_club','new_signing','new_foreign')
#head(epl)
#epl[factors] <- lapply(epl[factors] , factor)
names(epl)

train.index=sample(nrow(epl),nrow(epl)*0.75)
train=epl[train.index,]
test=epl[-train.index,]
```


Plots of some basic statistics. 

```{r}

#boxplots for all the categorical variables
par(mfrow=c(2,3))
#attacker=1,midfielders=2,defenders=3,goalkeepers=4
boxplot(epl$market_value~epl$position_cat,xlab='Player Nationality',ylab='Market Value (,000,000£)',names=c('Attacker','Midfielder','Defender','Goalkeeper'))
#Plays for top 6 clubs. (Arsenal,Chelsea,Liverpool,Manchester City,Manchester United,Tottenham)
boxplot(epl$market_value~epl$big_club,xlab='Club Prestige',ylab='Market Value (,000,000£)',names=c('Big Club','Non-Big Club'))
#what region in the world the player is from 1=England, 2=Rest of EU, 3=Americas, 4= Rest of World
boxplot(epl$market_value~epl$region,xlab='Player Nationality',ylab='Market Value (,000,000£)',names=c('England','EU','Americas','Rest of World'))
#Used to play in a different (foreign) league
boxplot(epl$market_value~epl$new_foreign,xlab='New Player from Foreign League',ylab='Market Value (,000,000£)',names=c('No','Yes'))
#Whether or not the player is a new signing (12 month playing or less)
boxplot(epl$market_value~epl$new_signing,ylab='Market Value (,000,000£)',names=c('Old Signing','New Signing'))


par(mfrow=c(2,3))
barplot(table(epl$position_cat))
barplot(table(epl$big_club))
barplot(table(epl$region))
barplot(table(epl$new_foreign))
barplot(table(epl$new_signing))
barplot(table(epl$age), xlab="Age", ylab="Market Value (,000,000£)")


par(mfrow=c(2,2))
hist(epl$market_value)
hist(epl$page_views)
hist(epl$fpl_value)
hist(epl$fpl_points)

summary(epl$big_club)
summary(epl$region)
summary(epl$new_foreign)
summary(epl$new_signing)

```

Corrlation plot shows which predictors are closely related to other variables. Note page_views, fpl_values, fpl_points, and big_club has large corrleations with market_value. 

```{r}

corrplot(cor(epl[c("age", "position_cat", "market_value", "page_views", "fpl_value", "fpl_points", "region", "new_foreign", "club_id", "big_club", "new_signing")]))



```


```{r}

#plot + cubic spline for the ages column
age.spline=lm(market_value~ns(age,4),epl)
x=seq(min(epl$age),max(epl$age),length=100)
y=predict(age.spline,newdata=data.frame(age=x),se=T)

plot(epl$age,epl$market_value,xlab='Player Age',ylab='Market Value (,000,000£)')
lines(x,y$fit,lwd=2)
lines(x,y$fit+2*y$se.fit,lty='dotted')
lines(x,y$fit-2*y$se.fit,lty='dotted')

```

Variable importance plots shows that page_views and fpl_value is the best predictor for market_value.

```{r}

rf_fit=randomForest(market_value~., data=train[c("age", "position_cat", "market_value", "page_views", "fpl_value", "fpl_points", "region", "new_foreign", "club_id", "big_club", "new_signing")])
(VI_F=importance(rf_fit))
#varImp(rf_fit)
varImpPlot(rf_fit,type=2)

```

Our linear model with the following predictors (age, position_cat, region, big_club, new_signing, new_foreign) gives us 102 test mean square error. 
```{r}

#linear model with forward/backward selection with age as linear term
epl.lmfit1=lm(market_value~age+position_cat+region+big_club+new_signing+new_foreign,train)
summary(epl.lmfit1)
epl.lmfit1.y = predict(epl.lmfit1, newdata=test)
mean((test$market_value-epl.lmfit1.y)^2)
```

We use backward and forward stepwise function to find best the best performing predictors.   

```{r}
start.model1=lm(market_value~1,data=epl)
end.model1  =lm(market_value~age+position_cat+region+big_club+new_signing+new_foreign,data=epl)

step(start.model1, scope=list(lower=start.model1,upper=end.model1),direction="forward")
step(end.model1, scope=list(lower=start.model1,upper=end.model1),direction="backward")
```

Our stepwise function found the best performing model (market_value~big_club+position_cat+new_signing+new_foreign) in this small scale search. The test MSE for this model is 102. 

```{r}

#both forward and backward model selection give the same outbut
epl.forwardfit1=lm(market_value~big_club+position_cat+new_signing+new_foreign,data=train)
summary(epl.forwardfit1)
epl.forwardfit1.y = predict(epl.forwardfit1, newdata=test)
mean((test$market_value-epl.forwardfit1.y)^2)
```

We try a linear model with natural spline  on predictor age and degree 3. Which gives us a test MSE of 83
```{r}


#linear model with forward/backward selection with splines for age term
epl.lmfit2=lm(market_value~ns(age,3)+position_cat+region+big_club+new_signing+new_foreign,train)
summary(epl.lmfit2)

epl.lmfit2.y = predict(epl.lmfit2, newdata=test)
mean((test$market_value-epl.lmfit2.y)^2)
```

We do a stepwise search with natural spline included in our model. The search found us this model (market_value ~ big_club + ns(age, 3) + position_cat + 
    new_signing). It has a test MSE of 81. 

```{r}
start.model2=lm(market_value~1,data=epl)
end.model2  =lm(market_value~ns(age,3)+position_cat+region+big_club+new_signing+new_foreign,data=epl)

step(start.model2, scope=list(lower=start.model2,upper=end.model2),direction="forward")
step(end.model2, scope=list(lower=start.model2,upper=end.model2),direction="backward")

#both forward and backward model selection give the same outbut
epl.forwardfit2=lm(market_value~big_club+ns(age,3)+position_cat+new_signing,data=train)

summary(epl.forwardfit2)

epl.forwardfit2.y = predict(epl.forwardfit2, newdata=test)
mean((test$market_value-epl.forwardfit2.y)^2)

```
The Normal QQ plot of the model residule is sorta linear. The error is almost gausian. 

```{r}

#checking normality of the residuals
par(mfrow=c(1,2))
qqnorm(epl.forwardfit2$resid)
qqline(epl.forwardfit2$resid)
hist(resid(epl.forwardfit2))

```
We try one last linear model with natural spline and all the one-hot predictors. We use the forward/backword stepwise search for predictors. The best performing AIC model is (market_value ~ fpl_value + page_views + ns(age, 
    3) + big_club + fpl_points + nationalityBelgium + positionDM + 
    nationalityNorway + `clubManchester+City` + nationalityFrance + 
    positionCF + clubChelsea + positionSS + clubSouthampton + 
    clubBurnley + `nationalityCzech Republic` + clubLiverpool + 
    nationalityEcuador + new_foreign + positionRW + positionLW)
    
It gives us the best test MSE with 30. 

```{r}
start.model3=lm(market_value~1,data=epl)
end.model3  =lm(market_value~ns(age,3) + .,data=epl)

#step(start.model3, scope=list(lower=start.model3,upper=end.model3),direction="forward")
#step(end.model3, scope=list(lower=start.model3,upper=end.model3),direction="backward")
all_pred_step <- step(start.model3, scope=list(lower=start.model3,upper=end.model3), direction="both")
print(all_pred_step$call)



```

market_value ~ fpl_value + big_club + page_views + positionCF + 
    positionDM + nationalityBelgium + age + fpl_points + nationalityEngland + 
    `clubManchester+City` + positionSS + nationalityFrance + 
    clubChelsea + nationalityNigeria + nationalityNorway + new_foreign + 
    `clubNewcastle+United` + nationalityScotland + nationalityArgentina + 
    nationalitySenegal + `clubBrighton+and+Hove` + `nationalityCzech Republic` + 
    clubLiverpool + positionLW + positionRW + clubSouthampton + 
    nationalityEcuador
    
    market_value ~ fpl_value + big_club + ns(age, 3) + 
    page_views + fpl_points + `clubManchester+City` + clubChelsea + 
    nationalityFrance + positionCF + nationalityBelgium + positionSS + 
    positionDM + clubBurnley + new_foreign + nationalityArgentina + 
    nationalityNorway + positionRM + clubBournemouth + nationalitySenegal + 
    clubSouthampton + nationalityEcuador + positionRW + positionLW + 
    nationalitySwitzerland
    
    market_value ~ fpl_value + page_views + ns(age, 
    3) + big_club + fpl_points + nationalityBelgium + positionDM + 
    nationalityNorway + `clubManchester+City` + nationalityFrance + 
    positionCF + clubChelsea + positionSS + clubSouthampton + 
    clubBurnley + `nationalityCzech Republic` + clubLiverpool + 
    nationalityEcuador + new_foreign + positionRW + positionLW

```{r}



epl.back.forward.fit=lm(market_value ~ fpl_value + page_views + ns(age, 
    3) + big_club + fpl_points + nationalityBelgium + positionDM + 
    nationalityNorway + `clubManchester+City` + nationalityFrance + 
    positionCF + clubChelsea + positionSS + clubSouthampton + 
    clubBurnley + `nationalityCzech Republic` + clubLiverpool + 
    nationalityEcuador + new_foreign + positionRW + positionLW ,data=train)

summary(epl.back.forward.fit)

epl.back.forward.y = predict(epl.back.forward.fit, newdata=test)
mean((test$market_value-epl.back.forward.y)^2)


```


```{r}

par(mfrow=c(2,2))
epl.tree =tree(market_value~age+position_cat+region+big_club+new_signing+new_foreign,train )
summary(epl.tree)

plot(epl.tree)
text(epl.tree,pretty=0)

cv.epl=cv.tree(epl.tree)
plot(cv.epl$size,cv.epl$dev,type='b')

prune.epl=prune.tree(epl.tree,best=8)

plot(prune.epl)
text(prune.epl,pretty=0)

```


```{r}

#initial tree test MSE
mean((test$market_value-predict(epl.tree,newdata=test))^2)

#pruned tree test MSE
mean((test$market_value-predict(prune.epl,newdata=test))^2)

#no learning benchmark ybar= mean of y in training data
mean((test$market_value-mean(train$market_value))^2)


```

We try the SVM model. First we standarize the data and resplit the train and test set. Next we fit market_value to all predictors and we have test MSE of 204

```{r}
#dropVars <- sapply(train, function(i) { if((is.numeric(i) & !any(is.nan(i)) & sd(i) > 0) | is.factor(i) | is.character(i)) TRUE else FALSE })
#smaller_train <- train[, dropVars]

#dropVars <- sapply(test, function(i) { if((is.numeric(i) & !any(is.nan(i)) & sd(i) > 0) | is.factor(i) | is.character(i)) TRUE else FALSE })
              
# subset test dropping columns that don't fit the criteria
#smaller_test <- test[, dropVars]

epl_ddf <- as.data.frame(sapply(epl, function(i) if(is.numeric(i)) scale(i) else i))
dropVars <- sapply(epl_ddf, function(i) { if((is.numeric(i) & !any(is.nan(i)) & sd(i) > 0) | is.factor(i) | is.character(i)) TRUE else FALSE })
epl_ddf <- epl_ddf[, dropVars]

train.index=sample(nrow(epl_ddf),nrow(epl_ddf)*0.75)
train=epl[train.index,]
test=epl[-train.index,]

#smaller_train
#test_ddf <- as.data.frame(sapply(test, function(i) if(is.numeric(i)) scale(i) else i))
#dropVars <- sapply(test_ddf, function(i) { if((is.numeric(i) & !any(is.nan(i)) & sd(i) > 0) | is.factor(i) | is.character(i)) TRUE else FALSE })
#smaller_test <- test_ddf[, dropVars]
#train
#test_ddf[is.na(test_ddf)]
#test_ddf %>% lapply(function(x){any(is.na(x))})

#summary(train_ddf)
svm.fit <- svm(market_value~., data=train)
svm.fit.y <- predict(svm.fit, newdata=test)

#summary(svm.fit)
mean((test$market_value-svm.fit.y)^2)
#svm.fit.y

```

We use the tune function to do SVM predictors search. The best model from this search gives a test MSE of . 

```{r}
tuneResult <- tune(svm, market_value ~ .,  data = train,
              ranges = list(epsilon = seq(0,1,0.1), cost = 2^(2:9))
)
print(tuneResult)
# Draw the tuning graph
plot(tuneResult)



```


```{r}
tunedModel <- tuneResult$best.model
tunedModelY <- predict(tunedModel, test) 
 
error <- test$model_value - tunedModelY  

 
# this value can be different on your computer
# because the tune method  randomly shuffles the data
#tunedModelRMSE <- rmse(error)  # 2.219642  
#print(tunedModelRMSE)
mean((test$market_value-tunedModelY)^2)

```



